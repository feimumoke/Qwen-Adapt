镜像：
ubuntu20.04-cuda11.8.0-py38-torch2.0.1-tf2.13.0-1.9.5


pip install transformers==4.34.0 accelerate tiktoken einops scipy transformers_stream_generator==0.0.4 peft deepspeed
pip install auto-gptq optimum


pip install packaging
pip install flash-attn --no-build-isolation
git clone https://github.com/Dao-AILab/flash-attention
cd flash-attention && pip install .
# Below are optional. Installing them might be slow.
pip install csrc/layer_norm
pip install csrc/rotary

python setup.py install

git config --global http.postBuffer 524288000



git clone https://github.com/feimumoke/Qwen-Adapt.git
cd Qwen-Adapt
pip install -r requirements_web_demo.txt


--train:

bash finetune/finetune_qlora_single_gpu.sh -m /mnt/workspace/.cache/modelscope/qwen/Qwen-14B-Chat-Int4 -d /mnt/workspace/Qwen-Adapt/train_data.json